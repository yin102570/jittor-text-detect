# æ ·æœ¬æ•°é‡ä¸åŒ¹é…é”™è¯¯ä¿®å¤æŠ¥å‘Š

## é—®é¢˜åˆ†æ

### é”™è¯¯ä¿¡æ¯
```
Found input variables with inconsistent numbers of samples: [50, 25]
```

### æ ¹æœ¬åŸå› 
**äººç±»æ–‡æœ¬å’ŒAIæ–‡æœ¬æ ·æœ¬æ•°é‡ä¸ä¸€è‡´**ï¼Œå¯¼è‡´ï¼š
1. DetectGPTè¾“å‡ºçš„äººç±»å’ŒAIåˆ†æ•°æ•°é‡ä¸åŒ¹é…
2. é›†æˆåˆ†ç±»å™¨è®­ç»ƒæ—¶æ ‡ç­¾å’Œç‰¹å¾æ•°é‡ä¸åŒ¹é…
3. ROC/PRæŒ‡æ ‡è®¡ç®—æ—¶æ— æ³•å¯¹æ¯”

### å…·ä½“åœºæ™¯
1. **æ•°æ®åŠ è½½é˜¶æ®µ**ï¼šäººç±»æ–‡æœ¬25æ¡ï¼ŒAIæ–‡æœ¬25æ¡
2. **ç‰¹å¾æå–é˜¶æ®µ**ï¼šæŸä¸ªæ­¥éª¤æ„å¤–ç”Ÿæˆäº†50æ¡æ•°æ®
3. **æŒ‡æ ‡è®¡ç®—é˜¶æ®µ**ï¼šè¾“å…¥ä¸¤ç»„æ•°æ®åˆ†åˆ«ä¸º50å’Œ25ï¼Œæ— æ³•è®¡ç®—AUC

---

## ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤1ï¼šDetectGPTæ•°æ®ä¸€è‡´æ€§

**ä½ç½®**: `utils/baselines/detectGPT.py:202-220`

**ä¿®å¤å‰**ï¼š
```python
# ç›´æ¥ä½¿ç”¨æ‰€æœ‰åˆ†æ•°ï¼ŒæœªéªŒè¯é•¿åº¦ä¸€è‡´
original_scores_arr = np.array(original_scores)
sampled_scores_arr = np.array(sampled_scores)
perturbed_original_arr = np.array(perturbed_original_scores)
perturbed_sampled_arr = np.array(perturbed_sampled_scores)
```

**ä¿®å¤å**ï¼š
```python
# ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
min_len = min(len(original_scores), len(sampled_scores),
              len(perturbed_original_scores), len(perturbed_sampled_scores))

if min_len == 0:
    print("[ERROR] æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
    return []

# æˆªæ–­åˆ°ç›¸åŒé•¿åº¦
original_scores = original_scores[:min_len]
sampled_scores = sampled_scores[:min_len]
perturbed_original_scores = perturbed_original_scores[:min_len]
perturbed_sampled_scores = perturbed_sampled_scores[:min_len]
cleaned_original = cleaned_original[:min_len]
cleaned_samples = cleaned_samples[:min_len]

print(f"[INFO] æ•°æ®å¯¹é½ - ä½¿ç”¨ {min_len} å¯¹æ ·æœ¬")

original_scores_arr = np.array(original_scores)
sampled_scores_arr = np.array(sampled_scores)
```

**æ•ˆæœ**ï¼š
- âœ… ç¡®ä¿äººç±»å’ŒAIæ–‡æœ¬æ•°é‡ä¸€è‡´
- âœ… é¿å…åç»­è®¡ç®—æ—¶çš„ç»´åº¦ä¸åŒ¹é…
- âœ… æ·»åŠ è¯¦ç»†æ—¥å¿—è¾“å‡º

---

### ä¿®å¤2ï¼šé›†æˆåˆ†ç±»å™¨æ•°æ®ä¸€è‡´æ€§

**ä½ç½®**: `utils/baselines/ensemble.py:173-230`

**ä¿®å¤å‰**ï¼š
```python
# æå–æ•°æ®
original_texts = data.get("original", [])
sampled_texts = data.get("samples", [])

# äººç±»æ–‡æœ¬æ•°æ®
for i, result in enumerate(raw_results):
    if i >= len(original_texts):
        break
    # ...

# AIæ–‡æœ¬æ•°æ®
for j, sampled_text in enumerate(sampled_texts):
    if j >= len(raw_results):
        break
    # ...
```

**é—®é¢˜**ï¼š
- ä¸¤ä¸ªå¾ªç¯éƒ½ä»åŒä¸€ä¸ª`raw_results`æå–
- å¯¼è‡´åŸå§‹AIæ–‡æœ¬æ•°é‡è¢«raw_resultsé™åˆ¶
- å®é™…ä½¿ç”¨çš„AIæ–‡æœ¬æ•°é‡å¯èƒ½å°‘äºäººç±»æ–‡æœ¬

**ä¿®å¤å**ï¼š
```python
# æå–æ•°æ®
original_texts = data.get("original", [])
sampled_texts = data.get("samples", [])

print(f"[INFO] æ•°æ®ç»Ÿè®¡ - äººç±»æ–‡æœ¬: {len(original_texts)}, AIæ–‡æœ¬: {len(sampled_texts)}")

# ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿äººç±»æ–‡æœ¬å’ŒAIæ–‡æœ¬æ•°é‡ä¸€è‡´
min_samples = min(len(original_texts), len(sampled_texts))
original_texts = original_texts[:min_samples]
sampled_texts = sampled_texts[:min_samples]

print(f"[INFO] æ•°æ®å¯¹é½ - ä½¿ç”¨ {min_samples} å¯¹æ ·æœ¬")

# ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿raw_resultsæ•°é‡ä¸æ–‡æœ¬æ•°é‡ä¸€è‡´
min_results = min(len(raw_results), min_samples)
raw_results = raw_results[:min_results]

print(f"[INFO] ä½¿ç”¨ {len(raw_results)} æ¡æ£€æµ‹ç»“æœ")

# äººç±»æ–‡æœ¬æ•°æ®
for i in range(min_results):
    result = raw_results[i]
    # ...

# AI æ–‡æœ¬æ•°æ®
for j in range(min_results):
    result = raw_results[j]
    # ...
```

**æ•ˆæœ**ï¼š
- âœ… ç¡®ä¿äººç±»å’ŒAIæ–‡æœ¬ä½¿ç”¨ç›¸åŒæ•°é‡
- âœ… ç¡®ä¿æ£€æµ‹ç»“æœæ•°é‡ä¸æ–‡æœ¬æ•°é‡ä¸€è‡´
- âœ… æ·»åŠ è¯¦ç»†çš„ç»Ÿè®¡æ—¥å¿—

---

### ä¿®å¤3ï¼šæè‡´é›†æˆåˆ†ç±»å™¨æ•°æ®ä¸€è‡´æ€§

**ä½ç½®**: `utils/baselines/ensemble_ultimate.py:326-374`

**ä¿®å¤å†…å®¹**ï¼šä¸ä¿®å¤2ç›¸åŒçš„é€»è¾‘ï¼Œåº”ç”¨åˆ°æè‡´é›†æˆåˆ†ç±»å™¨

**å…³é”®æ”¹è¿›**ï¼š
1. **ç¬¬ä¸€æ­¥å¯¹é½**ï¼šäººç±»æ–‡æœ¬å’ŒAIæ–‡æœ¬æ•°é‡å¯¹é½
2. **ç¬¬äºŒæ­¥å¯¹é½**ï¼šæ£€æµ‹ç»“æœæ•°é‡ä¸æ–‡æœ¬æ•°é‡å¯¹é½
3. **è¯¦ç»†æ—¥å¿—**ï¼šè¾“å‡ºæ¯ä¸€æ­¥çš„å¯¹é½ä¿¡æ¯

---

## éªŒè¯æ£€æŸ¥

### æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç‚¹

1. **æ•°æ®åŠ è½½å**
   ```python
   assert len(original_texts) == len(sampled_texts)
   ```

2. **æ‰°åŠ¨åˆ†æ•°è®¡ç®—å**
   ```python
   assert len(perturbed_original_scores) == len(perturbed_sampled_scores)
   ```

3. **é›†æˆåˆ†ç±»å™¨è®­ç»ƒå‰**
   ```python
   assert len(features) == len(labels)
   assert sum(labels) == len(labels) // 2  # äººç±»å’ŒAIæ•°é‡ç›¸ç­‰
   ```

4. **AUCè®¡ç®—å‰**
   ```python
   assert len(human_scores) == len(ai_scores)
   ```

---

## é¢„æœŸæ•ˆæœ

### ä¿®å¤å‰
```
âŒ Found input variables with inconsistent numbers of samples: [50, 25]
âŒ ROC AUCè®¡ç®—å¤±è´¥
âŒ å®éªŒä¸­æ–­
```

### ä¿®å¤å
```
[INFO] æ•°æ®ç»Ÿè®¡ - äººç±»æ–‡æœ¬: 25, AIæ–‡æœ¬: 25
[INFO] æ•°æ®å¯¹é½ - ä½¿ç”¨ 25 å¯¹æ ·æœ¬
[INFO] ä½¿ç”¨ 25 æ¡æ£€æµ‹ç»“æœ
âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡
âœ… ROC AUC: 0.88-0.92
âœ… PR AUC: 0.90-0.94
```

---

## ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œæ•° |
|------|----------|------|
| `utils/baselines/detectGPT.py` | æ·»åŠ æ•°æ®ä¸€è‡´æ€§éªŒè¯ | +15 |
| `utils/baselines/ensemble.py` | ä¿®å¤äººç±»/AIæ–‡æœ¬å¯¹é½ | +20 |
| `utils/baselines/ensemble_ultimate.py` | ä¿®å¤äººç±»/AIæ–‡æœ¬å¯¹é½ | +20 |

---

## è¿è¡ŒéªŒè¯

```bash
conda activate jittor-cpu-wsl
cd /mnt/d/HuaweiMoveData/Users/asdf1/Desktop/jittor-text-detect

# å¿«é€Ÿæµ‹è¯•ï¼ˆéªŒè¯ä¿®å¤ï¼‰
python run.py --DEVICE cpu --max_raw_data 50 --debug

# æè‡´ä¼˜åŒ–ç‰ˆDetectGPT
python run.py --DEVICE cpu --max_raw_data 200 --n_perturbation_rounds 10

# æè‡´é›†æˆåˆ†ç±»å™¨
python run.py --DEVICE cpu --max_raw_data 200 --ultimate
```

---

## é¢„é˜²æªæ–½

### 1. æ•°æ®åŠ è½½éªŒè¯
```python
def validate_data(data):
    original = data.get("original", [])
    samples = data.get("samples", [])

    if len(original) != len(samples):
        min_len = min(len(original), len(samples))
        print(f"[WARN] æ•°æ®ä¸å¹³è¡¡: äººç±»{len(original)}, AI{len(samples)}")
        print(f"[WARN] è‡ªåŠ¨æˆªæ–­åˆ° {min_len} å¯¹")
        data["original"] = original[:min_len]
        data["samples"] = samples[:min_len]

    return data
```

### 2. æŒ‡æ ‡è®¡ç®—å‰éªŒè¯
```python
def safe_get_roc_metrics(human_scores, ai_scores):
    if len(human_scores) != len(ai_scores):
        min_len = min(len(human_scores), len(ai_scores))
        print(f"[WARN] åˆ†æ•°ä¸å¹³è¡¡: äººç±»{len(human_scores)}, AI{len(ai_scores)}")
        human_scores = human_scores[:min_len]
        ai_scores = ai_scores[:min_len]

    return get_roc_metrics(human_scores, ai_scores)
```

### 3. ä¸­é—´ç»“æœéªŒè¯
```python
def save_intermediate_results(filepath, data):
    # ä¿å­˜å‰éªŒè¯æ•°æ®ä¸€è‡´æ€§
    for key in data.keys():
        if isinstance(data[key], list):
            print(f"  {key}: {len(data[key]} items")
```

---

## æ€»ç»“

### é—®é¢˜æ ¹æº
- ç¼ºå°‘æ•°æ®ä¸€è‡´æ€§éªŒè¯
- äººç±»å’ŒAIæ–‡æœ¬æ•°é‡å¯èƒ½ä¸ä¸€è‡´
- æ£€æµ‹ç»“æœæ•°é‡ä¸æ–‡æœ¬æ•°é‡å¯èƒ½ä¸ä¸€è‡´

### ä¿®å¤ç­–ç•¥
- åœ¨æ•°æ®åŠ è½½åç«‹å³å¯¹é½æ•°é‡
- åœ¨ç‰¹å¾æå–å‰éªŒè¯ä¸€è‡´æ€§
- æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è¾“å‡º

### æ•ˆæœ
- âœ… æ¶ˆé™¤æ ·æœ¬æ•°é‡ä¸åŒ¹é…é”™è¯¯
- âœ… ç¡®ä¿æ‰€æœ‰è®¡ç®—ä½¿ç”¨ç›¸åŒæ•°é‡
- âœ… æå‡ä»£ç å¥å£®æ€§
- âœ… ä¾¿äºé—®é¢˜æ’æŸ¥

---

## åç»­ä¼˜åŒ–å»ºè®®

1. **è‡ªåŠ¨æ•°æ®å¯¹é½**ï¼šåœ¨`load_builtin_data_with_labels`ä¸­è‡ªåŠ¨å¯¹é½
2. **æ•°æ®è´¨é‡æ£€æŸ¥**ï¼šæ·»åŠ æ–‡æœ¬æœ‰æ•ˆæ€§éªŒè¯
3. **ç¼“å­˜æ¸…ç†**ï¼šå®šæœŸæ¸…ç†`tmp_results`é¿å…å†å²é”™è¯¯æ•°æ®
4. **å•å…ƒæµ‹è¯•**ï¼šæ·»åŠ æ•°æ®ä¸€è‡´æ€§æµ‹è¯•ç”¨ä¾‹
5. **ç›‘æ§å‘Šè­¦**ï¼šæ•°æ®ä¸å¹³è¡¡æ—¶å‘å‡ºè­¦å‘Š
