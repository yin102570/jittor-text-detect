
import sys
import os
import random
import numpy as np

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import jittor as jt


def get_lls(args, config, texts):
    """
    è®¡ç®—ä¸€ç»„æ–‡æœ¬çš„å¯¹æ•°ä¼¼ç„¶ï¼ˆJittorç‰ˆæœ¬ï¼Œä¿®å¤lossè®¿é—®æ–¹å¼ï¼‰
    """
    base_model = config["base_model"]
    base_tokenizer = config["base_tokenizer"]

    lls = []
    for idx, text in enumerate(texts):
        try:
            # åˆ†è¯å¹¶è¿”å›Jittorå¼ é‡
            tokenized = base_tokenizer(
                text,
                return_tensors="jt",
                truncation=True,
                max_length=512
            )

            # è·å–input_idså¹¶ç¡®ä¿ç»´åº¦æ­£ç¡®
            input_ids = tokenized['input_ids']

            # ç¡®ä¿input_idsæ˜¯2ç»´å¼ é‡ [batch_size, seq_len]
            if isinstance(input_ids, list):
                input_ids = jt.array(input_ids)
            if len(input_ids.shape) == 1:
                input_ids = input_ids.unsqueeze(0)

            # labelså’Œinput_idsä¸€è‡´ï¼ˆè¯­è¨€æ¨¡å‹è‡ªå›å½’ä»»åŠ¡ï¼‰
            labels = input_ids.clone()

            # æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆè¿”å›å­—å…¸æ ¼å¼ï¼‰
            outputs = base_model(input_ids=input_ids, labels=labels)

            # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå­—å…¸ç”¨["loss"]è®¿é—®ï¼Œè€Œé.loss
            if isinstance(outputs, dict):
                # å­—å…¸ç±»å‹ï¼šå–lossé”®å€¼
                loss = outputs.get("loss", None)
                if loss is None:
                    # å¦‚æœå­—å…¸ä¸­æ²¡æœ‰lossé”®ï¼Œå°è¯•æ‰‹åŠ¨è®¡ç®—
                    print(f"âš ï¸ æ¨¡å‹è¿”å›å­—å…¸ä¸­æ— lossé”®ï¼Œå°è¯•æ‰‹åŠ¨è®¡ç®—ï¼ˆæ–‡æœ¬{idx + 1}/{len(texts)}ï¼‰")
                    logits = outputs.get("logits", None)
                    if logits is not None:
                        # æ‰‹åŠ¨è®¡ç®—äº¤å‰ç†µæŸå¤±
                        loss_fct = jt.nn.CrossEntropyLoss(ignore_index=0)
                        # ç§»ä½é¢„æµ‹ï¼ˆè¯­è¨€æ¨¡å‹æ ‡å‡†åšæ³•ï¼‰
                        shift_logits = logits[..., :-1, :].reshape(-1, logits.shape[-1])
                        shift_labels = labels[..., 1:].reshape(-1)
                        loss = loss_fct(shift_logits, shift_labels)
                    else:
                        raise ValueError("æ¨¡å‹è¿”å›å­—å…¸ä¸­æ—¢æ— lossä¹Ÿæ— logits")
            else:
                # å…¼å®¹å°‘æ•°æƒ…å†µè¿”å›ç±»å®ä¾‹çš„æƒ…å†µ
                loss = getattr(outputs, "loss", None)
                if loss is None:
                    raise ValueError("æ¨¡å‹è¿”å›å¯¹è±¡æ— losså±æ€§")

            # è½¬æ¢ä¸ºPythonæ•°å€¼ï¼Œå–è´Ÿå¾—åˆ°å¯¹æ•°ä¼¼ç„¶
            ll = -loss.item()
            lls.append(ll)

            # æ¯å¤„ç†10æ¡æ‰“å°è¿›åº¦
            if (idx + 1) % 10 == 0:
                print(f"âœ… å·²å¤„ç† {idx + 1}/{len(texts)} æ¡æ–‡æœ¬ï¼Œå½“å‰LL={ll:.4f}")

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡æœ¬ {idx + 1}/{len(texts)} å¤±è´¥: '{text[:50]}...'")
            print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
            lls.append(0.0)  # å…œåº•å€¼ï¼Œé¿å…ç¨‹åºä¸­æ–­

    return lls


def get_ll(args, config, text):
    """
    è®¡ç®—å•ä¸ªæ–‡æœ¬çš„å¯¹æ•°ä¼¼ç„¶ï¼ˆå¢åŠ å¼‚å¸¸å¤„ç†ï¼‰
    """
    try:
        return get_lls(args, config, [text])[0]
    except Exception as e:
        print(f"âŒ å•æ–‡æœ¬ä¼¼ç„¶è®¡ç®—å¤±è´¥: {str(e)}")
        return 0.0


class LikelihoodScorer:
    """
    ä¼¼ç„¶åº¦è¯„åˆ†å™¨ï¼ˆå¢å¼ºå¼‚å¸¸å¤„ç†ï¼‰
    """

    def __init__(self, args, config, L_samples=None):
        self.args = args
        self.config = config
        self.L_samples = L_samples

    def score(self, text):
        """å•æ–‡æœ¬è¯„åˆ†ï¼ˆå¢åŠ å¼‚å¸¸å…œåº•ï¼‰"""
        try:
            return get_ll(self.args, self.config, text)
        except Exception as e:
            print(f"âŒ LikelihoodScorerè¯„åˆ†å¤±è´¥: {str(e)}")
            return 0.0

    def score_texts(self, texts):
        """æ‰¹é‡æ–‡æœ¬è¯„åˆ†"""
        scores = []
        for idx, text in enumerate(texts):
            try:
                score = self.score(text)
                scores.append(score)
                if (idx + 1) % 10 == 0:
                    print(f"âœ… LikelihoodScorerå·²è¯„åˆ† {idx + 1}/{len(texts)} æ¡æ–‡æœ¬")
            except Exception as e:
                print(f"âŒ æ–‡æœ¬ {idx + 1} è¯„åˆ†å¤±è´¥: {str(e)}")
                scores.append(0.0)
        return scores


class PerturbationScorer:
    """
    æ‰°åŠ¨è¯„åˆ†å™¨ï¼ˆå¢å¼ºå¼‚å¸¸å¤„ç†å’Œç»´åº¦æ ¡éªŒï¼‰
    """

    def __init__(self, args, config, mask_filling_model, mask_filling_tokenizer):
        self.args = args
        self.config = config
        self.mask_filling_model = mask_filling_model
        self.mask_filling_tokenizer = mask_filling_tokenizer
        self.base_model = config["base_model"]
        self.base_tokenizer = config["base_tokenizer"]

    def _perturb_text(self, text):
        """æ–‡æœ¬æ‰°åŠ¨æ ¸å¿ƒé€»è¾‘ï¼ˆä¿®å¤generateå‚æ•°ä¸åŒ¹é…é—®é¢˜ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†ï¼‰"""
        try:
            # æ£€æŸ¥tokenizeræ˜¯å¦æœ‰tokenizeæ–¹æ³•
            if hasattr(self.base_tokenizer, 'tokenize'):
                tokens = self.base_tokenizer.tokenize(text)
            else:
                # å…œåº•ï¼šä½¿ç”¨encode+decodeæ¨¡æ‹Ÿtokenize
                token_ids = self.base_tokenizer.encode(text, truncation=True, max_length=512)
                tokens = [str(tid) for tid in token_ids]  # ç®€åŒ–å¤„ç†

            n_tokens = len(tokens)
            if n_tokens < 10:
                return text

            # è®¡ç®—æ©ç æ•°é‡
            n_mask = max(1, int(n_tokens * self.args.pct_words_masked))
            mask_positions = []

            # éšæœºé€‰æ‹©æ©ç ä½ç½®
            max_attempts = n_tokens * 2  # é˜²æ­¢æ­»å¾ªç¯
            attempts = 0
            while len(mask_positions) < n_mask and attempts < max_attempts:
                start = random.randint(0, max(0, n_tokens - self.args.span_length))
                span = list(range(start, min(start + self.args.span_length, n_tokens)))
                if not any(p in mask_positions for p in span):
                    mask_positions.extend(span)
                attempts += 1

            # åº”ç”¨æ©ç 
            masked_tokens = tokens.copy()
            mask_token = getattr(self.mask_filling_tokenizer, 'mask_token', '<mask>')
            for pos in mask_positions:
                if pos < len(masked_tokens):
                    masked_tokens[pos] = mask_token

            # è½¬æ¢å›æ–‡æœ¬
            if hasattr(self.base_tokenizer, 'convert_tokens_to_string'):
                masked_text = self.base_tokenizer.convert_tokens_to_string(masked_tokens)
            else:
                # å…œåº•ï¼šç®€å•æ‹¼æ¥
                masked_text = ' '.join(masked_tokens)

            # åˆ†è¯å¹¶ç”Ÿæˆå¡«å……æ–‡æœ¬
            inputs = self.mask_filling_tokenizer(
                masked_text,
                return_tensors="jt",
                truncation=True,
                max_length=512
            )

            # ç¡®ä¿input_idsç»´åº¦æ­£ç¡®
            input_ids = inputs.get('input_ids', inputs)
            if isinstance(input_ids, list):
                input_ids = jt.array(input_ids)
            if len(input_ids.shape) == 1:
                input_ids = input_ids.unsqueeze(0)

            # ç”Ÿæˆå¡«å……æ–‡æœ¬ - å…³é”®ä¿®å¤ï¼šç§»é™¤ä¸æ”¯æŒçš„num_beamså’Œdo_sampleå‚æ•°
            outputs = self.mask_filling_model.generate(
                input_ids=input_ids,
                max_length=min(n_tokens + 20, 512)
            )

            # è§£ç 
            filled_text = self.mask_filling_tokenizer.decode(
                outputs[0],
                skip_special_tokens=True
            )

            return filled_text.strip() if filled_text else text

        except Exception as e:
            print(f"âš ï¸ æ–‡æœ¬æ‰°åŠ¨å¤±è´¥: {str(e)}")
            return text  # è¿”å›åŸæ–‡æœ¬ä½œä¸ºå…œåº•

    def score(self, text):
        """å•æ–‡æœ¬æ‰°åŠ¨è¯„åˆ†ï¼ˆå¢åŠ å¼‚å¸¸å¤„ç† + å¤šé‡ä¼˜åŒ–æå‡AUCï¼‰"""
        try:
            # è®¡ç®—åŸå§‹æ–‡æœ¬ä¼¼ç„¶
            original_ll = get_ll(self.args, self.config, text)

            # ç”Ÿæˆæ‰°åŠ¨æ–‡æœ¬å¹¶è®¡ç®—ä¼¼ç„¶
            perturbed_lls = []
            for round_idx in range(self.args.n_perturbation_rounds):
                try:
                    perturbed_text = self._perturb_text(text)
                    if perturbed_text and perturbed_text != text:
                        perturbed_ll = get_ll(self.args, self.config, perturbed_text)
                        perturbed_lls.append(perturbed_ll)
                except Exception as e:
                    print(f"âš ï¸ æ‰°åŠ¨è½®æ¬¡ {round_idx + 1} å¤±è´¥: {str(e)}")
                    continue

            # è®¡ç®—å¹³å‡æ‰°åŠ¨ä¼¼ç„¶
            if not perturbed_lls:
                print("âš ï¸ æ‰€æœ‰æ‰°åŠ¨è½®æ¬¡å‡å¤±è´¥ï¼Œè¿”å›0åˆ†")
                return 0.0

            avg_perturbed_ll = np.mean(perturbed_lls)
            std_perturbed_ll = np.std(perturbed_lls) if len(perturbed_lls) > 1 else 0.0

            # åŸºç¡€æ›²ç‡åˆ†æ•°
            curvature = original_ll - avg_perturbed_ll

            # ğŸ”¥ ä¼˜åŒ–1: Z-score æ ‡å‡†åŒ–
            if std_perturbed_ll > 0:
                normalized_curvature = curvature / (std_perturbed_ll + 1e-8)
            else:
                normalized_curvature = curvature

            # ğŸ”¥ ä¼˜åŒ–2: å¤šè½®æ‰°åŠ¨ä¸€è‡´æ€§æ£€æŸ¥
            if len(perturbed_lls) >= 2:
                consistency = 1.0 / (1.0 + np.std(perturbed_lls))
            else:
                consistency = 1.0

            # ğŸ”¥ ä¼˜åŒ–3: å¹‚å‡½æ•°æ”¾å¤§åˆ†æ•°å·®å¼‚
            score = np.sign(curvature) * (np.abs(curvature) ** 0.8)

            # ğŸ”¥ ä¼˜åŒ–4: åŸå§‹ä¼¼ç„¶å½’ä¸€åŒ–ï¼ˆé¿å…é•¿åº¦åå·®ï¼‰
            text_length = len(text.split())
            normalized_original = original_ll / (text_length + 1)

            # ğŸ”¥ ä¼˜åŒ–5: ç»¼åˆè¯„åˆ†ç­–ç•¥
            # ç»“åˆæ›²ç‡ã€æ ‡å‡†å·®ã€ä¸€è‡´æ€§å’Œå½’ä¸€åŒ–åŸå§‹åˆ†æ•°
            final_score = (score * 0.5 +
                          normalized_curvature * 0.3 +
                          consistency * 0.1 +
                          normalized_original * 0.1)

            return final_score

        except Exception as e:
            print(f"âŒ PerturbationScorerè¯„åˆ†å¤±è´¥: {str(e)}")
            return 0.0

    def score_texts(self, texts):
        """æ‰¹é‡æ–‡æœ¬æ‰°åŠ¨è¯„åˆ†"""
        scores = []
        for idx, text in enumerate(texts):
            try:
                score = self.score(text)
                scores.append(score)
                if (idx + 1) % 5 == 0:
                    print(f"âœ… PerturbationScorerå·²è¯„åˆ† {idx + 1}/{len(texts)} æ¡æ–‡æœ¬")
            except Exception as e:
                print(f"âŒ æ–‡æœ¬ {idx + 1} æ‰°åŠ¨è¯„åˆ†å¤±è´¥: {str(e)}")
                scores.append(0.0)
        return scores