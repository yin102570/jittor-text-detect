#!/usr/bin/env python3
"""
AUC æè‡´ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•å¤šç§ä¼˜åŒ–ç­–ç•¥å¯¹ AUC çš„å½±å“
"""

import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import jittor as jt
from utils.setting import set_experiment_config, initial_setup
from utils.load_models_tokenizers import load_base_model_and_tokenizer, load_mask_filling_model
from utils.baselines.detectGPT import detectGPT
from utils.baselines.metric import get_roc_metrics, get_precision_recall_metrics

def test_auc_improvement():
    """æµ‹è¯• AUC æ”¹è¿›æ•ˆæœ"""

    print("=" * 60)
    print("ğŸš€ AUC æè‡´ä¼˜åŒ–æµ‹è¯•")
    print("=" * 60)

    # 1. é…ç½®ä¼˜åŒ–åçš„å‚æ•°
    class Args:
        dataset = 'builtin'
        max_raw_data = 100
        batch_size = 8
        n_perturbation_list = '15'
        base_model_name = 'gpt2'
        mask_filling_model_name = 't5-small'
        cache_dir = './cache'
        pct_words_masked = 0.25  # æå‡åˆ° 0.25
        span_length = 1  # é™ä½åˆ° 1
        n_perturbation_rounds = 15  # æå‡åˆ° 15
        DEVICE = 'auto'
        min_samples = 10

    args = Args()

    print(f"\nğŸ“Š ä¼˜åŒ–å‚æ•°é…ç½®:")
    print(f"  - æ©ç æ¯”ä¾‹: {args.pct_words_masked}")
    print(f"  - æ©ç è·¨åº¦: {args.span_length}")
    print(f"  - æ‰°åŠ¨è½®æ•°: {args.n_perturbation_rounds}")
    print(f"  - æ ·æœ¬æ•°é‡: {args.max_raw_data}")

    # 2. åŠ è½½æ•°æ®
    from run import load_builtin_data_with_labels
    data = load_builtin_data_with_labels(args)

    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  - åŸå§‹æ–‡æœ¬: {len(data.get('original', []))}")
    print(f"  - ç”Ÿæˆæ–‡æœ¬: {len(data.get('samples', []))}")

    # 3. åŠ è½½æ¨¡å‹
    print(f"\nğŸ”§ åŠ è½½æ¨¡å‹...")
    config = {}

    try:
        print(f"  - åŠ è½½åŸºç¡€æ¨¡å‹: {args.base_model_name}")
        config['base_model'], config['base_tokenizer'] = load_base_model_and_tokenizer(args)

        print(f"  - åŠ è½½æ©ç æ¨¡å‹: {args.mask_filling_model_name}")
        config['mask_model'], config['mask_tokenizer'] = load_mask_filling_model(args)

        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return

    # 4. è¿è¡Œä¼˜åŒ–åçš„ DetectGPT
    print(f"\nğŸ¯ è¿è¡Œæè‡´ä¼˜åŒ–ç‰ˆ DetectGPT...")
    print("-" * 60)

    results = detectGPT(args, config, data, span_length=args.span_length)

    if not results:
        print("\nâŒ DetectGPT è¿”å›ç©ºç»“æœ")
        return

    result = results[0]

    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆç»“æœ")
    print("=" * 60)

    metrics = result.get('metrics', {})
    roc_auc = metrics.get('roc_auc', 0)
    pr_auc = metrics.get('pr_auc', 0)

    print(f"\nğŸ¯ AUC æŒ‡æ ‡:")
    print(f"  - ROC AUC:  {roc_auc:.4f}")
    print(f"  - PR  AUC:  {pr_auc:.4f}")

    # è®¡ç®—ç¬¬ä¸‰ä¸ª AUC (F1 AUC)
    predictions = result.get('predictions', {})
    real_scores = predictions.get('real', [])
    sample_scores = predictions.get('samples', [])

    if real_scores and sample_scores:
        # è®¡ç®— F1 æ›²çº¿
        from sklearn.metrics import f1_score

        y_true = [1] * len(real_scores) + [0] * len(sample_scores)
        y_scores = real_scores + sample_scores

        # è®¡ç®—ä¸åŒé˜ˆå€¼ä¸‹çš„ F1 åˆ†æ•°
        thresholds = np.linspace(min(y_scores), max(y_scores), 100)
        f1_scores = []

        for threshold in thresholds:
            y_pred = [1 if score >= threshold else 0 for score in y_scores]
            try:
                f1 = f1_score(y_true, y_pred, zero_division=0)
                f1_scores.append(f1)
            except:
                f1_scores.append(0)

        # F1 AUC (ä½¿ç”¨é˜ˆå€¼ä½œä¸ºæ¨ªåæ ‡)
        from sklearn.metrics import auc as sk_auc
        thresholds_norm = (thresholds - thresholds.min()) / (thresholds.max() - thresholds.min() + 1e-8)
        f1_auc_value = sk_auc(thresholds_norm, f1_scores)

        print(f"  - F1  AUC:  {f1_auc_value:.4f}")

        # æ€»ä½“è¯„ä»·
        avg_auc = (roc_auc + pr_auc + f1_auc_value) / 3

        print(f"\nğŸ“ˆ å¹³å‡ AUC: {avg_auc:.4f}")

        # è¯„çº§
        if avg_auc >= 0.95:
            rating = "â­â­â­â­â­ å®Œç¾"
        elif avg_auc >= 0.90:
            rating = "â­â­â­â­ ä¼˜ç§€"
        elif avg_auc >= 0.85:
            rating = "â­â­â­ è‰¯å¥½"
        elif avg_auc >= 0.80:
            rating = "â­â­ åŠæ ¼"
        else:
            rating = "â­ éœ€æ”¹è¿›"

        print(f"ğŸ† ç»¼åˆè¯„çº§: {rating}")

        # æ”¹è¿›å»ºè®®
        if avg_auc < 0.85:
            print(f"\nğŸ’¡ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:")
            print(f"  1. å¢åŠ æ‰°åŠ¨è½®æ•°åˆ° 20+")
            print(f"  2. è°ƒæ•´æ©ç æ¯”ä¾‹åˆ° 0.30")
            print(f"  3. ä½¿ç”¨æ›´å¤§çš„æ ·æœ¬é›† (200+)")
            print(f"  4. å¯ç”¨é›†æˆåˆ†ç±»å™¨ (--ultimate)")

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    test_auc_improvement()
